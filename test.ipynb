{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"./hummingbird.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image import resize_activations, normalize_activations\n",
    "from utils.display import grid_display, heatmap_display\n",
    "from utils.saver import save_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_uint_255(image):\n",
    "    \"\"\"\n",
    "    Convert float images to int 0-255 images.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image. Can be either [0, 255], [0, 1], [-1, 1]\n",
    "    Returns:\n",
    "        numpy.ndarray:\n",
    "    \"\"\"\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "\n",
    "    if image.min() < 0:\n",
    "        image = (image + 1.0) / 2.0\n",
    "\n",
    "    return (image * 255).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_display(\n",
    "    heatmap, original_image, colormap=cv2.COLORMAP_JET, image_weight=0.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply a heatmap (as an np.ndarray) on top of an original image.\n",
    "\n",
    "    Args:\n",
    "        heatmap (numpy.ndarray): Array corresponding to the heatmap\n",
    "        original_image (numpy.ndarray): Image on which we apply the heatmap\n",
    "        colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "        image_weight (float): An optional `float` value in range [0,1] indicating the weight of\n",
    "            the input image to be overlaying the calculated attribution maps. Defaults to `0.7`\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Original image with heatmap applied\n",
    "    \"\"\"\n",
    "    heatmap = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "    image = image_to_uint_255(original_image)\n",
    "\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        cv2.cvtColor((heatmap * 255).astype(\"uint8\"), cv2.COLOR_GRAY2BGR), colormap\n",
    "    )\n",
    "\n",
    "    output = cv2.addWeighted(\n",
    "        cv2.cvtColor(image, cv2.COLOR_RGB2BGR), image_weight, heatmap, 1, 0\n",
    "    )\n",
    "\n",
    "    return cv2.cvtColor(output, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(\n",
    "        self,\n",
    "        validation_data,\n",
    "        model,\n",
    "        class_index,\n",
    "        input_shape=None,\n",
    "        colormap=cv2.COLORMAP_JET,\n",
    "        image_weight=0.7,\n",
    "        display_in_grid=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute GradCAM for a specific class index.\n",
    "\n",
    "        Args:\n",
    "            validation_data (Tuple[np.ndarray, Optional[np.ndarray]]): Validation data\n",
    "                to perform the method on. Tuple containing (x, y).\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "            class_index (int): Index of targeted class\n",
    "            input_shape (Tuple[int, int]): Shape of input data, e.g. (224, 224)\n",
    "            colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "            image_weight (float): An optional `float` value in range [0,1] indicating the weight of\n",
    "                the input image to be overlaying the calculated attribution maps. Defaults to `0.7`.\n",
    "            display_in_grid (bool): Whether display images on grid or separately.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Grid of all the GradCAM or 4D array (batch_size, height, width, channels)\n",
    "        \"\"\"\n",
    "        assert input_shape != None, \"Pass input shape argument\"\n",
    "\n",
    "        images, _ = validation_data\n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        # according to section 4.1 of paper, we need the last convolutional layer\n",
    "        layer_name = self.get_last_convolutional_layer_name(model)\n",
    "\n",
    "        # normalize feature maps, calculate masks and compute the\n",
    "        # output score\n",
    "        weights, maps = ScoreCAM.get_filters(\n",
    "            model, images, layer_name, class_index, input_shape\n",
    "        )\n",
    "\n",
    "        weights = weights.reshape((-1, 1, 1, batch_size)) # shape (K, 1, 1, 1)\n",
    "        weights = tf.reshape(weights, (batch_size, 1, 1, weights.shape[0])) # shape (1, 1, 1, K)\n",
    "\n",
    "        cam = ScoreCAM.generate_cam(weights, maps)\n",
    "\n",
    "        heatmaps = np.array(\n",
    "            [\n",
    "                # not showing the actual image if image_weight=0\n",
    "                heatmap_display(cam.numpy()[0], images[0], colormap, image_weight)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if display_in_grid:\n",
    "            return grid_display(heatmaps)\n",
    "        else:\n",
    "            return heatmaps\n",
    "\n",
    "def get_last_convolutional_layer_name(model):\n",
    "        \"\"\"\n",
    "        Search for the last convolutional layer to perform Score-CAM, as stated\n",
    "        in section 4.1 in the original paper.\n",
    "\n",
    "        Args:\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "\n",
    "        Returns:\n",
    "            str: Name of the target layer\n",
    "        \"\"\"\n",
    "        for layer in reversed(model.layers):\n",
    "            # Select closest 4D layer to the end of the network.\n",
    "            if len(layer.output_shape) == 4 and layer.name.count('conv') > 0:\n",
    "                return layer.name\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Model does not seem to contain 4D layer. Grad CAM cannot be applied.\"\n",
    "        )\n",
    "\n",
    "def generate_cam(weights, maps):\n",
    "        \"\"\"\n",
    "        Generate the Score-CAM\n",
    "\n",
    "        Inputs are the weights (shape Kx1x1xbatch_size) generated by the foward computing F(Mk)\n",
    "        followed by softmax activation and normalized maps (shape KxHxWx3)\n",
    "\n",
    "        Args:\n",
    "            weights (numpy.ndarray): Output score with shape (K, 1, 1, batch_size) where\n",
    "            K is the number of filters in the last convolutional layer\n",
    "            maps (tf.Tensor): 4D-Tensor with shape (K, H, W, batch_size) where K is the number\n",
    "            of filters in the last convolutional layer and H,W are the input image size\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: 4D-Tensor of linear weighted combination of all activation maps\n",
    "            with shape (batch_size, H, W, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        cam = tf.math.reduce_sum(tf.math.multiply(weights, maps), axis=-1, keepdims=True)\n",
    "\n",
    "        return cam\n",
    "\n",
    "def save(self, grid, output_dir, output_name):\n",
    "        \"\"\"\n",
    "        Save the output to a specific dir.\n",
    "\n",
    "        Args:\n",
    "            grid (numpy.ndarray): Grid of all the heatmaps\n",
    "            output_dir (str): Output directory path\n",
    "            output_name (str): Output name\n",
    "        \"\"\"\n",
    "\n",
    "        save_rgb(grid, output_dir, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "    input_shape = (224, 224)\n",
    "\n",
    "    img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=input_shape)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    data = (img, None)\n",
    "\n",
    "    tabby_cat_class_index = 94\n",
    "    explainer = ScoreCAM()\n",
    "    # Compute ScoreCAM on VGG16\n",
    "    image = explainer.explain(\n",
    "        data, model, tabby_cat_class_index, input_shape, display_in_grid=False\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = get_last_convolutional_layer_name(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block5_conv3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters(model, images, layer_name, class_index, input_shape):\n",
    "    \"\"\"\n",
    "    Generate guided gradients and convolutional outputs with an inference.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): tf.keras model to inspect\n",
    "        images (numpy.ndarray): 4D-Tensor with shape (batch_size, H, W, 3)\n",
    "        layer_name (str): Last convolutional layer\n",
    "        class_index (int): Index of targeted class\n",
    "        input_shape (Tuple[int, int]): Shape of input data, e.g. (224, 224)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[numpy.ndarray, tf.Tensor]: (Output score of given class, Normalized last conv outputs)\n",
    "    \"\"\"\n",
    "\n",
    "    conv_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(layer_name).output]\n",
    "    )\n",
    "    softmax_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.outputs]\n",
    "    )\n",
    "\n",
    "    inputs = tf.cast(images, tf.float32)\n",
    "\n",
    "    conv_output = conv_model(inputs)\n",
    "    resized_conv_output = resize_activations(conv_output, input_shape)\n",
    "    normalized_maps = normalize_activations(resized_conv_output) # shape (batch_size, H, W, K)\n",
    "    shape = normalized_maps.shape\n",
    "\n",
    "    # reshape normalized_maps tensor to shape (K, H, W, batch_size)\n",
    "    reshaped_normalized_maps = tf.reshape(normalized_maps, (shape[3], shape[1], shape[2], shape[0]))\n",
    "\n",
    "    masked_images = tf.math.multiply(reshaped_normalized_maps, inputs)\n",
    "        \n",
    "    classes_activation_scale = softmax_model.predict(masked_images)\n",
    "\n",
    "    # return the output only for the given class\n",
    "    weights = classes_activation_scale[:, class_index] # shape (K,)\n",
    "\n",
    "    return weights, normalized_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, maps = get_filters(model, data[0], layer_name, 94, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass = tf.math.multiply(weights, maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.reshape((-1, 1, 1, 1)) # shape (K, 1, 1, 1)\n",
    "weights = tf.reshape(weights, (1, 1, 1, weights.shape[0])) # shape (1, 1, 1, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 512), dtype=float32, numpy=\n",
       "array([[[[0.0020314 , 0.00202176, 0.00204512, 0.00202735, 0.00204637,\n",
       "          0.00203198, 0.0020267 , 0.00202486, 0.00201975, 0.00203711,\n",
       "          0.00202327, 0.00204954, 0.00203055, 0.00203785, 0.00203112,\n",
       "          0.00201535, 0.0020314 , 0.00202176, 0.00204365, 0.00202559,\n",
       "          0.00204531, 0.0020252 , 0.00202273, 0.00201243, 0.00201079,\n",
       "          0.00202624, 0.00201206, 0.00203238, 0.00201442, 0.00202326,\n",
       "          0.00200511, 0.00199878, 0.00199938, 0.00200157, 0.0020158 ,\n",
       "          0.00200618, 0.00201757, 0.00200114, 0.00199789, 0.00198292,\n",
       "          0.00199281, 0.00200073, 0.00200099, 0.00200172, 0.00200132,\n",
       "          0.00199734, 0.00198845, 0.00198914, 0.00197858, 0.0019963 ,\n",
       "          0.00199572, 0.00200743, 0.00200036, 0.00200242, 0.00198828,\n",
       "          0.00197847, 0.00199017, 0.00199101, 0.00200674, 0.00198585,\n",
       "          0.00200504, 0.00198516, 0.00199759, 0.00198898, 0.00198008,\n",
       "          0.00199814, 0.00197898, 0.00200579, 0.00198395, 0.00201351,\n",
       "          0.00198226, 0.00200743, 0.00199512, 0.00199478, 0.00200458,\n",
       "          0.00197233, 0.00202077, 0.00198165, 0.00204283, 0.0019969 ,\n",
       "          0.00201889, 0.0020108 , 0.00198325, 0.00202859, 0.00198741,\n",
       "          0.00202302, 0.00198931, 0.00206458, 0.00201614, 0.00202223,\n",
       "          0.00202587, 0.00196512, 0.00200627, 0.00199008, 0.00201538,\n",
       "          0.00200812, 0.00200861, 0.00201737, 0.0019425 , 0.00201066,\n",
       "          0.00197056, 0.00195856, 0.00198421, 0.0019226 , 0.00201076,\n",
       "          0.00189198, 0.00203252, 0.00192225, 0.00195582, 0.00198359,\n",
       "          0.00187326, 0.00200302, 0.00184373, 0.00202304, 0.00182702,\n",
       "          0.00198944, 0.00196701, 0.0019246 , 0.00198377, 0.00177849,\n",
       "          0.00201822, 0.00175622, 0.00202313, 0.00190383, 0.00197063,\n",
       "          0.00197535, 0.00182227, 0.00201517, 0.00170681, 0.00201774,\n",
       "          0.00180895, 0.00202252, 0.00197326, 0.00193629, 0.00201459,\n",
       "          0.00175548, 0.00203916, 0.00177874, 0.00202283, 0.00190859,\n",
       "          0.00202289, 0.00202521, 0.00187168, 0.00207092, 0.00175188,\n",
       "          0.00199759, 0.00183045, 0.00205968, 0.00197244, 0.00195417,\n",
       "          0.00206997, 0.0017571 , 0.00203315, 0.00179861, 0.00199652,\n",
       "          0.00190904, 0.00201227, 0.00201395, 0.00184841, 0.00204755,\n",
       "          0.00174789, 0.00193375, 0.00184691, 0.00204563, 0.00193465,\n",
       "          0.00190502, 0.00205204, 0.00171609, 0.00195054, 0.00178854,\n",
       "          0.00191855, 0.00190583, 0.00192536, 0.00198009, 0.00177062,\n",
       "          0.00195748, 0.00174152, 0.00178928, 0.00185407, 0.00188052,\n",
       "          0.00192327, 0.00179849, 0.00194902, 0.00169306, 0.00179922,\n",
       "          0.00177584, 0.00177171, 0.00189713, 0.00176911, 0.00195545,\n",
       "          0.00167729, 0.00182197, 0.00175354, 0.00166751, 0.00184118,\n",
       "          0.00169883, 0.0019092 , 0.00164894, 0.00188749, 0.00169085,\n",
       "          0.00169496, 0.00176687, 0.00166434, 0.00187886, 0.00164055,\n",
       "          0.00193715, 0.00162574, 0.00175776, 0.00179466, 0.00159128,\n",
       "          0.00185407, 0.00159787, 0.00191434, 0.00160158, 0.0018605 ,\n",
       "          0.00172955, 0.00166435, 0.00180321, 0.00158481, 0.00187952,\n",
       "          0.0015526 , 0.00191726, 0.00160368, 0.00173541, 0.00178571,\n",
       "          0.00153089, 0.00186198, 0.00151533, 0.00193662, 0.00153074,\n",
       "          0.00184203, 0.00173074, 0.00163951, 0.00181967, 0.00151317,\n",
       "          0.00188148, 0.00148163, 0.0019011 , 0.0016067 , 0.00172544,\n",
       "          0.0017759 , 0.00152846, 0.0018729 , 0.00148691, 0.00193807,\n",
       "          0.00154452, 0.00184511, 0.00172724, 0.00165413, 0.00184612,\n",
       "          0.00150939, 0.00190134, 0.00150652, 0.00190962, 0.00165686,\n",
       "          0.00174961, 0.00178129, 0.00156386, 0.00191246, 0.00144744,\n",
       "          0.00193809, 0.00157095, 0.0018518 , 0.00172024, 0.00166064,\n",
       "          0.00187925, 0.00146948, 0.00194301, 0.00147171, 0.00191486,\n",
       "          0.00165629, 0.00174285, 0.00179909, 0.00154233, 0.0019403 ,\n",
       "          0.00137684, 0.00195071, 0.00156447, 0.00183132, 0.00174083,\n",
       "          0.00164109, 0.00191285, 0.00144853, 0.00196775, 0.00146456,\n",
       "          0.00193596, 0.00166344, 0.00173094, 0.00182665, 0.00156378,\n",
       "          0.00196776, 0.00138746, 0.00197291, 0.0015719 , 0.0018682 ,\n",
       "          0.00176817, 0.00164672, 0.00194541, 0.00148242, 0.00199315,\n",
       "          0.00152339, 0.00196055, 0.00167731, 0.00176597, 0.0018565 ,\n",
       "          0.00160997, 0.00199439, 0.00144414, 0.00199605, 0.00158768,\n",
       "          0.00190601, 0.00177548, 0.00168851, 0.00195322, 0.0015222 ,\n",
       "          0.00201149, 0.00153423, 0.00197698, 0.00169434, 0.00181855,\n",
       "          0.00187174, 0.00167282, 0.00199837, 0.00150895, 0.00200999,\n",
       "          0.00157939, 0.00193821, 0.00180096, 0.00176798, 0.00195711,\n",
       "          0.00158112, 0.00201079, 0.00155002, 0.00198234, 0.0017515 ,\n",
       "          0.00186635, 0.0018879 , 0.00176556, 0.00199651, 0.00157437,\n",
       "          0.00201805, 0.00162199, 0.00195332, 0.00187423, 0.00185335,\n",
       "          0.0019646 , 0.00163973, 0.00200919, 0.00157793, 0.00197621,\n",
       "          0.00182082, 0.00188925, 0.00190712, 0.00179857, 0.00199567,\n",
       "          0.00163161, 0.00201775, 0.00167299, 0.00193516, 0.00190139,\n",
       "          0.00187195, 0.00197611, 0.00169665, 0.00200271, 0.00163363,\n",
       "          0.00195842, 0.00184787, 0.0018875 , 0.00193097, 0.00178561,\n",
       "          0.00199259, 0.00166351, 0.0020056 , 0.00171629, 0.00189891,\n",
       "          0.00191061, 0.0018375 , 0.00198129, 0.00169555, 0.0019994 ,\n",
       "          0.00164523, 0.00193177, 0.00184986, 0.0018479 , 0.00193973,\n",
       "          0.00176126, 0.00199021, 0.00165206, 0.00198345, 0.00176679,\n",
       "          0.0018979 , 0.0019146 , 0.00183418, 0.00198543, 0.0017385 ,\n",
       "          0.00200106, 0.00173911, 0.00191956, 0.00188567, 0.00187926,\n",
       "          0.00196899, 0.00180498, 0.0019941 , 0.00174235, 0.00196525,\n",
       "          0.00184054, 0.00190113, 0.0019392 , 0.00185261, 0.00199299,\n",
       "          0.00175414, 0.00200383, 0.00181318, 0.00191093, 0.00189103,\n",
       "          0.00187016, 0.00198579, 0.00178854, 0.00199848, 0.00176264,\n",
       "          0.00194638, 0.00184911, 0.00188547, 0.00195677, 0.0018399 ,\n",
       "          0.00199622, 0.00174758, 0.00200208, 0.00184883, 0.00191383,\n",
       "          0.00191179, 0.00187355, 0.00198411, 0.00181286, 0.00199557,\n",
       "          0.00184266, 0.0019526 , 0.00188016, 0.0019192 , 0.0019753 ,\n",
       "          0.00187506, 0.00199619, 0.00182473, 0.00199847, 0.00190189,\n",
       "          0.00194859, 0.00194747, 0.0019151 , 0.00198606, 0.00187542,\n",
       "          0.00199759, 0.00192575, 0.00196966, 0.00192554, 0.00195582,\n",
       "          0.00197606, 0.00192134, 0.00200247, 0.00193229, 0.0020009 ,\n",
       "          0.00194338, 0.00198192, 0.00197621, 0.00196176, 0.00200444,\n",
       "          0.00195401, 0.0020184 , 0.0019781 , 0.00200407, 0.00196595,\n",
       "          0.00198156, 0.00200843, 0.0019777 , 0.00204132, 0.00200496,\n",
       "          0.00203246, 0.00198461, 0.00200689, 0.00202291, 0.00200256,\n",
       "          0.0020436 , 0.00202923, 0.00206118, 0.00201401, 0.00205291,\n",
       "          0.00201878, 0.00200991, 0.00204555, 0.00204986, 0.00208173,\n",
       "          0.00204304, 0.0020725 , 0.00202325, 0.00205288, 0.00205471,\n",
       "          0.00203397, 0.00206831, 0.00204962, 0.00208331, 0.00202401,\n",
       "          0.00207283, 0.00203608, 0.00202768, 0.00205591, 0.00205892,\n",
       "          0.00208509, 0.00204022, 0.00207764, 0.00202513, 0.00205508,\n",
       "          0.00205471, 0.00203397]]]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
